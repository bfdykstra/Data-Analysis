{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3\n",
    "\n",
    "In this edition, I predict restuarant revenue using [ridge](https://en.wikipedia.org/wiki/Tikhonov_regularization) and  [lasso](https://en.wikipedia.org/wiki/Lasso_(statistics)) regression. Then I use [elastic](https://en.wikipedia.org/wiki/Elastic_net_regularization) regularization to 'combine' the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train = pd.read_csv(\"Problem8_train.csv\")\n",
    "test = pd.read_csv(\"Problem8_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>P9</th>\n",
       "      <th>P10</th>\n",
       "      <th>...</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2740687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5461700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3818055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6836483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4554237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   P1   P2   P3   P4  P5  P6  P7  P8  P9  P10   ...     P29  P30  P31  P32  \\\n",
       "0   2  3.0  4.0  3.0   1   5   5   5   5    5   ...     3.0    5    5    5   \n",
       "1   3  5.0  4.0  4.0   2   5   5   4   5    4   ...     2.0    0    0    0   \n",
       "2   4  5.0  4.0  4.0   2   3   5   4   4    4   ...     2.0    4    1    2   \n",
       "3   3  5.0  4.0  4.0   2   2   5   1   4    4   ...     2.0    5    5    3   \n",
       "4   4  5.0  5.0  4.0   1   5   5   3   4    5   ...     1.0    5    5    4   \n",
       "\n",
       "   P33  P34  P35  P36  P37  revenue  \n",
       "0    3    4    4    3    1  2740687  \n",
       "1    0    0    0    0    0  5461700  \n",
       "2    2    3    4    3    2  3818055  \n",
       "3    3    3    4    3    2  6836483  \n",
       "4    3    3    4    4    1  4554237  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify correct features, add constants to independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train.values[:,0:37]#all values except for revenue\n",
    "y_train = train[['revenue']].values #revenue\n",
    "x_test = test.values[:,1:38]\n",
    "\n",
    "x_train, x_test = sm.add_constant(x_train), sm.add_constant(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scale paramters\n",
    "sc = StandardScaler()\n",
    "x_train_std = sc.fit_transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ridge regression, we try a variety of lambdas so that we get the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best lambda for Ridge Regression:  50.0\n",
      "\n",
      "                              The R2:  0.209628592221\n"
     ]
    }
   ],
   "source": [
    "RR = linear_model.RidgeCV(alphas = [0.01, 0.05, 0.1, 1, 5, 10, 25, 50])\n",
    "RR.fit(x_train_std, y_train)\n",
    "best_lambda1 = RR.alpha_\n",
    "print\n",
    "print \"The best lambda for Ridge Regression: \", best_lambda1\n",
    "print\n",
    "print\"                              The R2: \", RR.score(x_train_std, y_train)\n",
    "#run model on the test set\n",
    "y_test_pred_ridge = RR.predict(x_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is lasso regression, which performs significantly better than Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best lasso lambda:  65.0\n",
      "\n",
      "               The R2:  0.460497119868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lasso regression on scaled data\n",
    "lasso = linear_model.LassoCV(alphas = [.01, .05, .1, 1, 5, 10, 25, 50, 55, 65])\n",
    "lasso.fit(x_train_std, np.ravel(y_train))\n",
    "best_lambda2 = lasso.alpha_\n",
    "print\n",
    "print \"The best lasso lambda: \", best_lambda2\n",
    "print\n",
    "print \"               The R2: \",lasso.score(x_train_std, y_train)\n",
    "print\n",
    "#run it again on test set\n",
    "y_test_pred_lasso = lasso.predict(x_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hit it now with elastic regularization, which also significantly detracts from the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best lambda:  5.0\n",
      "\n",
      "         The R2:  0.114136377136\n"
     ]
    }
   ],
   "source": [
    "elastic = linear_model.ElasticNetCV(alphas = [.01, .05, .1, 1, \n",
    "                                              5, 10, 25, 50, 65])\n",
    "elastic.fit(x_train_std, np.ravel(y_train))\n",
    "best_lambda2 = elastic.alpha_\n",
    "print\n",
    "print \"The best lambda: \", best_lambda2\n",
    "print\n",
    "print \"         The R2: \", elastic.score(x_train_std, y_train)\n",
    "#run it again on test set\n",
    "y_test_pred_elastic = elastic.predict(x_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison's sake, we'll do a regular OLS on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.461\n",
      "Model:                            OLS   Adj. R-squared:                  0.139\n",
      "Method:                 Least Squares   F-statistic:                     1.430\n",
      "Date:                Tue, 06 Sep 2016   Prob (F-statistic):              0.105\n",
      "Time:                        15:26:53   Log-Likelihood:                -1578.5\n",
      "No. Observations:                 100   AIC:                             3233.\n",
      "Df Residuals:                      62   BIC:                             3332.\n",
      "Df Model:                          37                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const       6.195e+06   4.39e+06      1.411      0.163     -2.58e+06   1.5e+07\n",
      "x1          2.633e+05   4.19e+05      0.629      0.532     -5.74e+05   1.1e+06\n",
      "x2         -2.587e+04   4.13e+05     -0.063      0.950     -8.52e+05     8e+05\n",
      "x3         -4.254e+05   4.46e+05     -0.954      0.344     -1.32e+06  4.66e+05\n",
      "x4         -4.245e+05   7.02e+05     -0.605      0.548     -1.83e+06  9.79e+05\n",
      "x5         -1.362e+05   4.91e+05     -0.277      0.782     -1.12e+06  8.45e+05\n",
      "x6          9.113e+04   2.41e+05      0.378      0.706      -3.9e+05  5.72e+05\n",
      "x7          1.734e+05   2.87e+05      0.603      0.548     -4.01e+05  7.48e+05\n",
      "x8         -7.392e+05   5.99e+05     -1.234      0.222     -1.94e+06  4.58e+05\n",
      "x9          7.294e+05    1.2e+06      0.608      0.545     -1.67e+06  3.13e+06\n",
      "x10        -1.148e+06   1.82e+06     -0.632      0.530     -4.78e+06  2.48e+06\n",
      "x11         1.901e+05   3.48e+05      0.546      0.587     -5.06e+05  8.87e+05\n",
      "x12         5.666e+04   8.41e+05      0.067      0.947     -1.63e+06  1.74e+06\n",
      "x13         2.067e+05   1.63e+06      0.127      0.899     -3.05e+06  3.46e+06\n",
      "x14        -5.603e+05   4.91e+05     -1.142      0.258     -1.54e+06  4.21e+05\n",
      "x15         1.583e+05   5.79e+05      0.273      0.785     -9.99e+05  1.32e+06\n",
      "x16        -8.443e+05   5.97e+05     -1.414      0.162     -2.04e+06  3.49e+05\n",
      "x17         6.989e+05   4.79e+05      1.458      0.150     -2.59e+05  1.66e+06\n",
      "x18         1.064e+06   5.48e+05      1.943      0.057     -3.07e+04  2.16e+06\n",
      "x19        -1.773e+05   2.09e+05     -0.849      0.399     -5.95e+05   2.4e+05\n",
      "x20        -4.783e+05   1.93e+05     -2.481      0.016     -8.64e+05  -9.3e+04\n",
      "x21         8.166e+05   3.95e+05      2.069      0.043      2.77e+04  1.61e+06\n",
      "x22        -6178.4742   3.25e+05     -0.019      0.985     -6.56e+05  6.44e+05\n",
      "x23         3.923e+04   1.48e+05      0.266      0.791     -2.56e+05  3.34e+05\n",
      "x24         2.601e+05   6.39e+05      0.407      0.685     -1.02e+06  1.54e+06\n",
      "x25         8.806e+05   7.11e+05      1.239      0.220      -5.4e+05   2.3e+06\n",
      "x26        -1.355e+06   7.56e+05     -1.792      0.078     -2.87e+06  1.56e+05\n",
      "x27         -2.72e+05   2.97e+05     -0.916      0.363     -8.65e+05  3.21e+05\n",
      "x28         9.618e+05   3.47e+05      2.775      0.007      2.69e+05  1.65e+06\n",
      "x29         7.537e+05   4.47e+05      1.687      0.097     -1.39e+05  1.65e+06\n",
      "x30         5.258e+05   2.82e+05      1.861      0.067     -3.89e+04  1.09e+06\n",
      "x31         8.969e+04   4.73e+05      0.190      0.850     -8.55e+05  1.03e+06\n",
      "x32         -4.49e+05   5.25e+05     -0.856      0.395      -1.5e+06     6e+05\n",
      "x33        -7.459e+05   5.56e+05     -1.340      0.185     -1.86e+06  3.67e+05\n",
      "x34         6.401e+05   5.06e+05      1.266      0.210     -3.71e+05  1.65e+06\n",
      "x35        -1.715e+05   4.45e+05     -0.386      0.701     -1.06e+06  7.18e+05\n",
      "x36        -8.498e+05   1.14e+06     -0.746      0.459     -3.13e+06  1.43e+06\n",
      "x37         9.788e+05    5.2e+05      1.884      0.064     -5.97e+04  2.02e+06\n",
      "==============================================================================\n",
      "Omnibus:                       38.010   Durbin-Watson:                   1.674\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               93.314\n",
      "Skew:                           1.395   Prob(JB):                     5.46e-21\n",
      "Kurtosis:                       6.823   Cond. No.                         528.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "ols = sm.OLS(y_train, x_train)\n",
    "print ols.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Lasso regression performs the best, and comparably to regular OLS. So there is no real advantage in this case to use Lasso over OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
